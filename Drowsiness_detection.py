# -*- coding: utf-8 -*-
"""Drowsiness_Detection_Monsurat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xvOGZMuceXxIeSKIRu6-2p9G0uagig53

*Load Drive*
"""

from google.colab import drive
drive.mount('/content/drive')

"""*Import Libraries*"""

import os
import glob
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np# Keras API
import keras
from keras.models import Sequential
from sklearn.model_selection import GridSearchCV
from keras.layers import Dense,Dropout,Flatten
from keras.layers import Conv2D,MaxPooling2D,Activation,AveragePooling2D,BatchNormalization
from keras.preprocessing.image import ImageDataGenerator

"""*Load Training and Testing Set*"""

train_path = '/content/drive/MyDrive/Colab Notebooks/train_drowsy'
test_path = '/content/drive/MyDrive/Colab Notebooks/test_drowsy'
val_path = '/content/drive/MyDrive/Colab Notebooks/test_drowsy'

"""*Count number of training and testing Images*"""

def get_files(directory):
  if not os.path.exists(directory):
    return 0
  count=0

  for current_path,dirs,files in os.walk(directory):
    for dr in dirs:
      count+= len(glob.glob(os.path.join(current_path,dr+"/*")))
  return count

"""*Display the number*"""

train_samples = get_files(train_path)
num_classes = len(glob.glob(train_path+"/*"))
test_samples = get_files(test_path)
val_samples = get_files(val_path)

print("Number of classes is", num_classes)
print("Number of training samples is", train_samples)
print("Number of testing samples is", test_samples)
print("Number of validation samples is", val_samples)

"""*Image Augmentation*"""

train_datagen = ImageDataGenerator(rescale=1./255,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

val_datagen = ImageDataGenerator(rescale=1./255)

img_width, img_height = 50, 50

input_shape = (img_width, img_height, 3)

batch_size = 32

train_generator = train_datagen.flow_from_directory(train_path,
                                                   target_size = (img_width, img_height),
                                                   batch_size = batch_size)

test_generator = test_datagen.flow_from_directory(test_path,
                                                  shuffle = False,
                                                  target_size = (img_width, img_height),
                                                  batch_size = batch_size)

val_generator = val_datagen.flow_from_directory(val_path,
                                                shuffle = False,
                                                target_size = (img_width, img_height),
                                                batch_size = batch_size)
# Get x_train and y_train
x_train, y_train = train_generator.next()

# Get x_test and y_test
x_test, y_test = test_generator.next()

# Get x_val and y_val
x_val, y_val = val_generator.next()

"""*Get Class Index*"""

train_generator.class_indices

"""*Build CNN Parameters*"""

model = Sequential()
model.add(Conv2D(32, (5, 5),input_shape=input_shape,activation='relu'))
model.add(MaxPooling2D(pool_size=(3, 3)))
model.add(Conv2D(32, (3, 3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, (3, 3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(512,activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(128,activation='relu'))
model.add(Dense(num_classes,activation='softmax'))
model.summary()

"""*Build Model*"""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Compile the model with the specified optimizer, loss, and metrics
opt = tf.keras.optimizers.Adam(learning_rate = 0.001)
model.compile(
    optimizer = opt,
    loss = 'categorical_crossentropy',
    metrics = ['accuracy'])

# Define callbacks
early_stopping = EarlyStopping(
    monitor = 'val_accuracy',
    patience = 5,
    restore_best_weights = True)

model_checkpoint = ModelCheckpoint(
    'new_drowsiness_model.h5',
    monitor = 'val_accuracy',
    save_best_only = True)

# Train the model with the specified callbacks
history = model.fit(
    train_generator,
    steps_per_epoch = len(train_generator),
    validation_data = test_generator,
    validation_steps = len(test_generator),
    verbose = 1,
    epochs = 50,
    callbacks = [early_stopping, model_checkpoint]
)

"""*Plot Accuracy and Losses*"""

import matplotlib.pyplot as plt

# Extract data from the history object
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)

# Plotting side by side
fig, axs = plt.subplots(1, 2, figsize=(14, 5))  # 1 row, 2 columns

# Plot Training and Validation accuracy
axs[0].plot(epochs, acc, 'b', label='Training accuracy')
axs[0].plot(epochs, val_acc, 'r', label='Validation accuracy')
axs[0].set_title('Training and Validation Accuracy')
axs[0].set_xlabel('Epochs')
axs[0].set_ylabel('Accuracy')
axs[0].legend()

# Plot Training and Validation loss
axs[1].plot(epochs, loss, 'b', label='Training loss')
axs[1].plot(epochs, val_loss, 'r', label='Validation loss')
axs[1].set_title('Training and Validation Loss')
axs[1].set_xlabel('Epochs')
axs[1].set_ylabel('Loss')
axs[1].legend()

plt.tight_layout()  # Adjust the layout to prevent overlap
plt.show()

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)
#Train and validation accuracy
plt.plot(epochs, acc, 'b', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and Validation accuracy')
plt.xlabel('Epochs')  # Label for the x-axis
plt.ylabel('Accuracy')  # Label for the y-axis
plt.legend()

plt.figure()
#Train and validation loss
plt.plot(epochs, loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and Validation loss')
plt.legend()
plt.show()

"""*Evaluate Model Accuracy*"""

score,accuracy = model.evaluate(val_generator, verbose = 1)
print("Validation score is {:.2f}%".format(score*100))
print("Validation accuracy is {:.2f}%".format(accuracy*100))

"""*Load Saved Model for Testing*"""

from keras.models import load_model
model=load_model('/content/new_drowsiness_model.h5')

Classes = ['Drowsy', 'Non_Drowsy']

"""*Classification Report*"""

from sklearn.metrics import classification_report,confusion_matrix
y_test = test_generator.classes

# predicting our model with test dataset i.e. unseen dataset
pred = model.predict(test_generator, test_samples//batch_size+1,verbose=1,).argmax(axis=1)

#print(y_test)
print(pred)

#Classification report of every label
print(classification_report(y_test, pred, target_names = Classes))

"""*Prediction Accuracy*"""

correct = 0
incorrect = 0
for i in range(len(y_test)):

    #print("Test Sample is: ", y_test[i], "while predicted sample is: ", pred[i])

    if y_test[i] != pred[i]:
        incorrect += 1
    else:
        correct += 1

print('Total number of test cases', ((len(y_test))))
print('Number of correct predictions', correct)
print('Number of incorrect predictions', incorrect)

"""*Plot Confusion Matrix*"""

import pandas as pd
import seaborn as sn

# Create a confusion matrix
conf_mat = confusion_matrix(y_test, pred)

# Create a DataFrame from the confusion matrix
conf_df = pd.DataFrame(conf_mat, columns = Classes, index = Classes)

# Plot the confusion matrix using seaborn with annotated actual and predicted labels
plt.figure(figsize = (6, 5))
plt.title('Confusion Matrix of Drowsiness Detection')
sn.heatmap(conf_df, fmt = "d", cmap = "Blues", annot = True, cbar = False, linewidths = .5)

# Add x and y axis labels
plt.xlabel('Predicted Labels')
plt.ylabel('Actual Labels')

plt.show()

"""*Test Single Image*"""

from google.colab import files
from keras.models import load_model
from PIL import Image
import numpy as np
from IPython.display import display, Image as IPImage, Audio

# Upload the Keras model file (replace 'best_drowsiness_model.h5' with your actual model file)
uploaded = files.upload()

# Load the model
model = load_model('/content/new_drowsiness_model.h5')  # Replace 'best_drowsiness_model.h5' with your actual model file

# Define your classes (replace 'Classes' with your actual class labels)
Classes = ['Drowsy', 'Non_Drowsy']

def classify_image(file_path):
    test_image = Image.open(file_path)
    test_image = test_image.resize((50, 50))
    test_image = np.expand_dims(np.array(test_image), axis=0)

    result = model.predict(test_image)
    predicted_class = np.argmax(result)
    sign = Classes[predicted_class]

    print(f'The Predicted class is: {predicted_class}')
    print(f'The Predicted sign is: {sign}')

    # Display the image
    display(IPImage(filename=file_path))

    # Check if drowsy is detected and play an alarm sound
    if sign == 'Drowsy':
        alarm_sound_url = 'https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3'  # Replace with your alarm sound URL
        display(Audio(url=alarm_sound_url, autoplay=True))

# Ask the user to choose a file
file_path = list(uploaded.keys())[0]  # Get the first uploaded file
classify_image(file_path)